{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a8b399-50ff-4d60-bf95-c80f0bc887ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\ydool\\Repos\\sensor-analysis-assignment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b6a291-959b-4b85-bf4e-598a26b18fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_features import process_dataset, load_and_process_sample\n",
    "from visualization import signal_viewer\n",
    "from imu_pipeline import IMUPipeline\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7165b8b-235f-4a05-85ad-038a4f3784ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c6297510ba4a849006b1aa16acc659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Sample ID:', layout=Layout(width='50%'), options=('00104b76-d512-43d6-b2e…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "signal_viewer(\n",
    "    data_dir=Path('data/raw/train'),\n",
    "    labels_csv=Path('data/train.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0319cf27-f9e4-470b-9218-8b5bd4f9d0b9",
   "metadata": {},
   "source": [
    "# ❓ Questions to Reflect On\n",
    "\n",
    "\n",
    "- What do you observe when comparing the model’s predictions on the new data to its known performance?\n",
    "\n",
    "- Is there anything in the data that might explain differences in behavior?\n",
    "\n",
    "- Can you identify patterns or trends related to when the model succeeds or fails?\n",
    "\n",
    "- Are there signals or features that seem to affect the model’s reliability?\n",
    "\n",
    "- What could be done in the short term to handle the current situation?\n",
    "\n",
    "- What are potential long-term steps to improve model performance in similar scenarios?\n",
    "\n",
    "- What would you want to explore further if given more time or data?\n",
    "\n",
    "- What assumptions did the model rely on during training — and are they still valid?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f22028c-6de5-4e42-a90f-70f92383b73a",
   "metadata": {},
   "source": [
    "##### Analysis of test data vs. inference data\n",
    "# note: I used chatGPT to understand what the columns are, as I couldn't find a description of the columns in the task. So if a column is misinterpreted that's a context-availability problem as I am unfamliar with this data. \n",
    "\n",
    "The cause I found for the difference in performance is that driver vehicle data somehow got mangled. \n",
    "The easiest way to see if when looking at data that should be the same for a vehicle across sessions - device_model, calibration_status, firmware_version, sensor_source, network_type\n",
    "if you look at cell 162 in the notebook where I filtered for driver_id D1071, and you can see that according to the data, he has 3 vehicles, they have different sensor sources and firmware versions and different calibration status and network types, but in cell 164 when the info for the same driver is filtered, magically there is only 1 row per vehicle.\n",
    "My intuition says something's wrong with the data pipeline or the way these data points arrive in the pipeline. I don't have access to Source of Truth data so I can't say for sure.\n",
    "\n",
    "Short term solution is to remove from the pipeline all the session ids from the inference run (they do not overlap with the test data, so we keep the good data).Also if I had access to the pipeline and source of truth data I would remove anything else that could have the same issues.\n",
    "Long term, this would need to be fixed and monitored. I'd add a validation script that checks for these issues and flags them as they enter the database.\n",
    "\n",
    "While investigating the 2 datasets, I found these to be true for both:\n",
    "-firmware version affects model performance (older version - worse results)\n",
    "-time of day affects model performance (worst in the afternoon, suggesting that the model works well for day time and night when things are either bright or dark, and less so in the inbetween condition)\n",
    "-vehicle type - SUVs seem to have worse detection rate\n",
    "-weather - fog decreases performance (which makes sense, it also decreases the human driver's performance because of the limited visibility)\n",
    "\n",
    "Adding training data for older firmware versions, afternoon rides and SUVs seems like it could improve performance. \n",
    "\n",
    "I would like more explanations of the data before exploring it further, but assuming everything chatGPT told me about the columns is correct, given more time I'd explore the model performance relative to different types of vehicle movements, and also I would like to have this data separated into highways and residential streets and dirt roads (and any other road type) because those are very different car motions, indication of the other traffic on the road (other cars have a lot of influence on a vehicle's motion), and also I would like more info on the vehicle - is it electric or gas, size (smaller cars can feel very different from larger cars, or at least for the smaller car I used to have in 2012, it felt a bit wobbly when the winds were high), also speaking of wind weather info could be useful, or maybe just an indication if there are strong winds as this affects a car's movement as well (or at least the care i used to have).\n",
    "\n",
    "Regarding model assumptions relied on during training - I can't say for sure, it seems to be that the assumptions are along the lines of - everyone has a car or a truck, is driving at morning or at night, with the latest firmware. so diversifying that data would be the key to solving that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27106c87-fa3a-4817-86ac-1d95f14d799c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7d57b-4d05-40b6-8c94-e62922789fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e6e42-3312-4093-9b55-19523e874fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
